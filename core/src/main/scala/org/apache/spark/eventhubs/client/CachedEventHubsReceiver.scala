/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.spark.eventhubs.client

import java.time.Duration
import java.util.concurrent.{Callable, Executors, ScheduledExecutorService}

import com.google.common.cache._
import com.microsoft.azure.eventhubs._
import org.apache.commons.lang3.concurrent.BasicThreadFactory
import org.apache.spark.eventhubs._
import org.apache.spark.eventhubs.utils.EventHubsReceiverListener
import org.apache.spark.eventhubs.utils.RetryUtils.{retryJava, retryNotNull}
import org.apache.spark.internal.Logging
import org.apache.spark.{SparkEnv, TaskContext}

import scala.collection.JavaConverters._
import scala.concurrent.ExecutionContext.Implicits.global
import scala.concurrent.{Await, Awaitable, Future}
import scala.util.{Failure, Success, Try}

private[spark] trait CachedReceiver {
  private[eventhubs] def receive(
      ehConf: EventHubsConf,
      nAndP: NameAndPartition,
      requestSeqNo: SequenceNumber,
      batchSize: Int,
      eventHubsReceiverListener: Option[EventHubsReceiverListener] = None): Iterator[EventData]
}

/**
 * An Event Hubs receiver instance that is cached on a Spark Executor to be
 * reused across batches. In Structured Streaming and Spark Streaming,
 * partitions are generated on the same executors across batches, so that
 * receivers can be cached are reused for maximum efficiency. Receiver caching
 * allows the underlying [[PartitionReceiver]]s to prefetch [[EventData]] from
 * the service before DataFrames or RDDs are generated by Spark.
 *
 * This class creates and maintains an AMQP link with the Event Hubs service.
 * On creation, an [[EventHubClient]] is borrowed from the [[ClientConnectionPool]].
 * Then a [[PartitionReceiver]] is created on top of the borrowed connection with the
 * [[NameAndPartition]].
 *
 * @param ehConf the [[EventHubsConf]] which contains the connection string used to connect to Event Hubs
 * @param nAndP  the Event Hub name and partition that the receiver is connected to.
 */
private[client] class CachedEventHubsReceiver private (ehConf: EventHubsConf,
                                                       nAndP: NameAndPartition,
                                                       startSeqNo: SequenceNumber)
    extends Logging {

  type AwaitTimeoutException = java.util.concurrent.TimeoutException

  import org.apache.spark.eventhubs._

  private def getClientAndReceiver(seqNo: SequenceNumber, createNew: Boolean = false): (EventHubClient, PartitionReceiver) = {
    def createReceiver(client: EventHubClient,
                       seqNo: SequenceNumber): Future[PartitionReceiver] = {

      val start = System.currentTimeMillis()
      logInfo(
        s"creating receiver for Event Hub ${nAndP.ehName} on partition ${nAndP.partitionId}. seqNo: $seqNo")
      val consumerGroup = ehConf.consumerGroup.getOrElse(DefaultConsumerGroup)
      val receiverOptions = new ReceiverOptions
      receiverOptions.setReceiverRuntimeMetricEnabled(true)
      receiverOptions.setPrefetchCount(ehConf.prefetchCount.getOrElse(DefaultPrefetchCount))
      receiverOptions.setIdentifier(
        s"spark-${SparkEnv.get.executorId}-${TaskContext.get.taskAttemptId}")
      val epochReceiver = retryJava(
        client.createEpochReceiver(consumerGroup,
          nAndP.partitionId.toString,
          EventPosition.fromSequenceNumber(seqNo).convert,
          DefaultEpoch,
          receiverOptions),
        "CachedReceiver creation."
      )
      logInfo(s"Receiver created, creation takes ${System.currentTimeMillis() - start} milliseconds")
      epochReceiver.map(_._1)
    }
    if (createNew) {
      CachedEventHubsReceiver.resourceCache.invalidate(CacheKey(ehConf.connectionString, nAndP.partitionId.toString))
    }
    val (ehClient, _, receiver, _) = CachedEventHubsReceiver.resourceCache
      .get(
        CacheKey(ehConf.connectionString, nAndP.partitionId.toString),
        new Callable[(EventHubClient, ScheduledExecutorService, PartitionReceiver, EventHubsConf)] {
          override def call(): (EventHubClient,
                          ScheduledExecutorService,
                          PartitionReceiver,
                          EventHubsConf) = {
            val connStr = ConnectionStringBuilder(ehConf.connectionString)
            connStr.setOperationTimeout(ehConf.operationTimeout.getOrElse(DefaultOperationTimeout))
            val threadFactory = new BasicThreadFactory.Builder()
              .namingPattern(s"ehClient-for-${this.getClass.getSimpleName}-${ConnectionStringBuilder(
                ehConf.connectionString).getNamespace}-${connStr.getEventHubName}-${nAndP.partitionId}-%d")
              .build()
            val threadPool = Executors.newScheduledThreadPool(1, threadFactory)
            val client = EventHubClient.createSync(connStr.toString, threadPool)
            (client,
              threadPool,
              Await.result(createReceiver(client, seqNo), ehConf.internalOperationTimeout),
              ehConf)
          }
        }
      )
    (ehClient, receiver)
  }

  private def lastReceivedOffset(receiver: PartitionReceiver): Long = {
    if (receiver.getEventPosition.getSequenceNumber != null) {
      receiver.getEventPosition.getSequenceNumber
    } else {
      -1
    }
  }


  private def receiveOne(reciever: PartitionReceiver, timeout: Duration, msg: String): Future[Iterable[EventData]] = {
    receive(reciever, timeout, 1, msg)
  }

  private def receive(receiver: PartitionReceiver,
                       timeout: Duration,
                      maxEventCount: Int,
                      msg: String): Future[Iterable[EventData]] = {
      receiver.setReceiveTimeout(timeout)
      retryNotNull(receiver.receive(maxEventCount), msg).map(_.asScala)
  }

  private def checkCursor(initialClient: EventHubClient, initialReceiver: PartitionReceiver, requestSeqNo: SequenceNumber): (Future[Iterable[EventData]], EventHubClient, PartitionReceiver) = {
    var receiver = initialReceiver
    var client = initialClient
    val lastReceivedSeqNo = lastReceivedOffset(receiver)

    if (lastReceivedSeqNo > -1 && lastReceivedSeqNo + 1 != requestSeqNo) {
      logInfo(
        s"checkCursor. Recreating a receiver for $nAndP, ${ehConf.consumerGroup}. requestSeqNo: $requestSeqNo, lastReceivedSeqNo: $lastReceivedSeqNo")
      getClientAndReceiver(requestSeqNo, createNew = true) match {
        case (_client, _receiver) =>
          client = _client
          receiver = _receiver
      }
    }

    val event = awaitReceiveMessage(
      receiveOne(receiver, ehConf.receiverTimeout.getOrElse(DefaultReceiverTimeout), "checkCursor initial"),
      requestSeqNo)
    val receivedSeqNo = event.head.getSystemProperties.getSequenceNumber

    val result = if (receivedSeqNo != requestSeqNo) {
      // This can happen in two cases:
      // 1) Your desired event is still in the service, but the receiver
      //    cursor is in the wrong spot.
      // 2) Your desired event has expired from the service.
      // First, we'll check for case (1).
      logInfo(
        s"checkCursor. requested sequence number is not match last received sequence number, recreating a receiver for $nAndP, ${ehConf.consumerGroup}. requestSeqNo: $requestSeqNo, receivedSeqNo: $receivedSeqNo")
      getClientAndReceiver(requestSeqNo, createNew = true) match {
        case (_client, _receiver) =>
          client = _client
          receiver = _receiver
      }
      val movedEvent = awaitReceiveMessage(
        receiveOne(receiver, ehConf.receiverTimeout.getOrElse(DefaultReceiverTimeout), "checkCursor move"),
        requestSeqNo)
      val movedSeqNo = movedEvent.head.getSystemProperties.getSequenceNumber
      if (movedSeqNo != requestSeqNo) {
        // The event still isn't present. It must be (2).
        logInfo("The first event not present, the requested event must be expired")
        val info = Await.result(
          retryJava(
            client.getPartitionRuntimeInformation(nAndP.partitionId.toString),
            "partitionRuntime",
            ehConf.operationRetryTimes.getOrElse(RetryCount),
            ehConf.operationRetryExponentialDelayMs.getOrElse(10)
          ).map(_._1),
          ehConf.internalOperationTimeout
        )

        if (requestSeqNo < info.getBeginSequenceNumber &&
            movedSeqNo == info.getBeginSequenceNumber) {
          Future {
            movedEvent
          }
        } else {
          val consumerGroup = ehConf.consumerGroup.getOrElse(DefaultConsumerGroup)
          throw new IllegalStateException(
            s"In partition ${info.getPartitionId} of ${info.getEventHubPath}, with consumer group $consumerGroup, " +
              s"request seqNo $requestSeqNo is less than the received seqNo $receivedSeqNo. The earliest seqNo is " +
              s"${info.getBeginSequenceNumber} and the last seqNo is ${info.getLastEnqueuedSequenceNumber}")
        }
      } else {
        Future {
          movedEvent
        }
      }
    } else {
      Future {
        event
      }
    }
    (result, client, receiver)
  }

  private def receive(
      requestSeqNo: SequenceNumber,
      batchSize: Int,
      eventHubsReceiverListener: Option[EventHubsReceiverListener]): Iterator[EventData] = {
    var (client, receiver) = getClientAndReceiver(requestSeqNo)
    val retryCount = ehConf.receiveRetryTimes.getOrElse(DefaultReceiveRetryTimes)
    var retried = 0
    var finalResult: Option[Iterator[EventData]] = None
    var finalException: Option[Throwable] = None
    while (retried < retryCount && finalResult.isEmpty) {
      retried += 1
      Try {
        val start = System.currentTimeMillis()
        // Retrieve the events. First, we get the first event in the batch.
        // Then, if the succeeds, we collect the rest of the data.
        val firstFuture = checkCursor(client, receiver, requestSeqNo) match {
          case (_firstFuture, _client, _receiver) =>
            client = _client
            receiver = _receiver
            _firstFuture
        }
        val first = Await.result(firstFuture, ehConf.internalOperationTimeout)
        val firstSeqNo = first.head.getSystemProperties.getSequenceNumber
        val newBatchSize = (requestSeqNo + batchSize - firstSeqNo).toInt
        eventHubsReceiverListener.foreach(_.onReceiveFirstEvent(nAndP, first.head))

        if (newBatchSize <= 0) {
          return Iterator.empty
        }

        var theRest = Seq.empty[EventData]
        while (theRest.size < newBatchSize - 1) {
          theRest = theRest ++ awaitReceiveMessage(
            receive(receiver, ehConf.receiverTimeout.getOrElse(DefaultReceiverTimeout),
                    Math.min(500, newBatchSize - 1 - theRest.size),
                    s"receive; $nAndP"),
            requestSeqNo)
        }
        theRest = theRest.take(newBatchSize - 1)
        // Combine and sort the data.
        val combined = first ++ theRest
        val sorted = combined.toSeq
          .sortWith((e1, e2) =>
            e1.getSystemProperties.getSequenceNumber < e2.getSystemProperties.getSequenceNumber)
          .iterator
        val (result, validate) = sorted.duplicate
        finalResult = Some(result)
        val receivedBytes = validate.map(_.getBytes.size.toLong).sum
        val elapsed = System.currentTimeMillis() - start
        eventHubsReceiverListener.foreach(listener => {
          listener.onBatchReceiveSuccess(nAndP, elapsed, newBatchSize, receivedBytes)
        })
        (newBatchSize, receivedBytes, elapsed)
      } match {
        case Success((receivedMessages, receivedBytes, elapsed)) =>
          logInfo(
            s"receive succeed for [${ehConf.namespace}:$nAndP], received $receivedMessages messages, $receivedBytes bytes, takes: $elapsed milliseconds, throughput: ${receivedBytes.toDouble / elapsed} bytes / millisecond")
        case Failure(exception) =>
          finalException = Some(exception)
          logWarning("Receive failure", exception)
          logInfo(
            s"Receive failure. Recreating a receiver for [${ehConf.namespace}:$nAndP], ${ehConf.consumerGroup}. requestSeqNo: $requestSeqNo")
          getClientAndReceiver(requestSeqNo, createNew = true) match {
            case (_client, _receiver) =>
              client = _client
              receiver = _receiver
          }
      }
    }
    finalResult.getOrElse({
      val errorMessage = s"failed to read events: " +
        s"${ConnectionStringBuilder(ehConf.connectionString).getEndpoint.getHost}-${nAndP.ehName}:${nAndP.partitionId}, " +
        s"requestSeqNo: $requestSeqNo, batchSize: $batchSize"
      finalException match {
        case Some(exception) =>
          logError(
            errorMessage
            , exception)
          throw exception
        case None =>
          logError(errorMessage)
          throw new RuntimeException(errorMessage)
      }
    })
  }

  private def awaitReceiveMessage[T](awaitable: Awaitable[T], requestSeqNo: SequenceNumber): T = {
    try {
      Await.result(awaitable, ehConf.internalOperationTimeout)
    } catch {
      case e: AwaitTimeoutException =>
        logError(
          s"awaitReceiveMessage call failed with timeout. Event Hub $nAndP, ConsumerGroup ${ehConf.consumerGroup}. requestSeqNo: $requestSeqNo")
        throw e
    }
  }
}

case class CacheKey(connectionString: String, partitionId: String)

/**
 * A companion object to the [[CachedEventHubsReceiver]]. This companion object
 * serves as a singleton which carries all the cached receivers on a given
 * Spark executor.
 */
private[spark] object CachedEventHubsReceiver extends CachedReceiver with Logging {

  type MutableMap[A, B] = scala.collection.mutable.HashMap[A, B]

  private[this] val receivers = new MutableMap[String, CachedEventHubsReceiver]()

  private def key(ehConf: EventHubsConf, nAndP: NameAndPartition): String = {
    (ehConf.connectionString + ehConf.consumerGroup + nAndP.partitionId).toLowerCase
  }

  private[eventhubs] override def receive(
      ehConf: EventHubsConf,
      nAndP: NameAndPartition,
      requestSeqNo: SequenceNumber,
      batchSize: Int,
      eventHubsReceiverListener: Option[EventHubsReceiverListener] = None): Iterator[EventData] = {
    logInfo(
      s"EventHubsCachedReceiver look up. For $nAndP, ${ehConf.consumerGroup}. requestSeqNo: $requestSeqNo, batchSize: $batchSize")
    var receiver: CachedEventHubsReceiver = null
    receivers.synchronized {
      receiver = receivers.getOrElseUpdate(key(ehConf, nAndP), {
        CachedEventHubsReceiver(ehConf, nAndP, requestSeqNo)
      })
    }
    receiver.receive(requestSeqNo, batchSize, eventHubsReceiverListener)
  }

  val resourceCache
    : Cache[CacheKey, (EventHubClient, ScheduledExecutorService, PartitionReceiver, EventHubsConf)] = CacheBuilder
    .newBuilder()
    .maximumSize(16)
    .removalListener(
      new RemovalListener[CacheKey, (EventHubClient, ScheduledExecutorService, PartitionReceiver, EventHubsConf)] {
        override def onRemoval(
      notification: RemovalNotification[
        CacheKey,
        (EventHubClient,
         ScheduledExecutorService,
         PartitionReceiver,
         EventHubsConf)]): Unit = {
          val (client, executorService, receiver, ehConf) = notification.getValue
          Future {
            Try {
              Await.ready(Future {
                receiver.closeSync()
              }, ehConf.internalOperationTimeout)
            } match {
              case Success(_) => logInfo(s"receiver closed succeed")
              case Failure(exception) => logWarning("close receiver failed", exception)
            }
            Try{
              Await.ready(Future {
                client.closeSync()
              }, ehConf.internalOperationTimeout)
            } match {
              case Success(_) => logInfo("client closed succeed")
              case Failure(exception) => logWarning("close client failed", exception)
            }
            Try{
              Await.ready(Future {
                executorService.shutdown()
              }, ehConf.internalOperationTimeout)
            } match {
              case Success(_) => logInfo("thread pool closed succeed")
              case Failure(exception) => logWarning("close thread pool failed", exception)
            }
          }
        }
      })
    .build()

  def apply(ehConf: EventHubsConf,
            nAndP: NameAndPartition,
            startSeqNo: SequenceNumber): CachedEventHubsReceiver = {
    new CachedEventHubsReceiver(ehConf, nAndP, startSeqNo)
  }
}
